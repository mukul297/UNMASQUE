#! /usr/bin/env python
#  -*- coding: utf-8 -*-
#
# GUI module generated by PAGE version 5.0.3
#  in conjunction with Tcl version 8.6
#    Mar 21, 2020 10:05:19 AM IST  platform: Windows NT
# from google.cloud.sql.connector import connector
# from google.cloud.sql.connector import IPTypes
# import pg8000
#new reveal.py = reveal.py + reveal_support.py + reveal_proc.py + reveal_proc_support.py
# import mysql.connector
from pickle import TRUE
from flask import *
import csv
import sys
import threading
import time
from flask import Flask, render_template
from turbo_flask import Turbo
import random
app = Flask(__name__)
turbo = Turbo(app)


app.secret_key="dsl@iisc"
app.SQLALCHEMY_DATABASE_URI = "postgresql://postgres:@localhost/tpch"
status=0

import sys



sys.path.append('./extraction_pipeline/')
import error_handler
import platform
import threading
import os
import reveal_globals
# import reveal_op
import time

# import reveal_db
import time
import copy
import os
import from_clause
import db_minimizer
import error_handler
import initialization
import where_clause
import projection
import groupby_clause
import aggregation
import orderby_clause
import limit





try:
    import pyodbc
except ImportError:
    pass


import psycopg2





import os.path




def extracted_part_info():
	print("inside:   reveal_proc_support.extracted_part_info")
	return {'SELECT':reveal_globals.global_select_op_proc.strip(),\
		  'FROM':reveal_globals.global_from_op.strip(),\
		  'WHERE':reveal_globals.global_where_op.strip(),\
		  'GROUP BY':reveal_globals.global_groupby_op.strip(),\
		  'ORDER BY':reveal_globals.global_orderby_op.strip(),\
		  'LIMIT': reveal_globals.global_limit_op.strip()}




def reveal_vp_start_gui():
    global status
    print("inside reveal.vp_start_gui")
    if 'windows' in str(platform.system()).lower():
        reveal_globals.global_os_name = 'windows'
    else:
        reveal_globals.global_os_name = 'linux'
    runreveal()
    # reveal_support_init()
    




def runreveal(*args):
    print("inside------reveal_support.runreveal")
    '''if reveal_globals.global_test_option == '':
        return'''
    if reveal_globals.global_input_type != "1":
        reveal_globals.global_input_type = "0"
    if reveal_globals.global_conn == None:
        if(not establishConnection()):
            return
    #CHECK FOR STORED PROCEDURE EXISTENCE AND ERROR HERE BY RUNNING ON SOME SAMPLE DATABASE
    #CLOSE THIS SCREEN AND CALL THE NEXT SCREEN
    reveal_globals.global_proc_prev_screen = "inp"
    extractionStart()
 


# def getconn() :
#     conn=connector.connect(
#         "sneha-354311:asia-south1:postgres1",
#         "pg8000",
#         user="postgres",
#         password="root",
#         db="tpch"
#     )
#     return conn


def getconn():
    conn = psycopg2.connect(
        database="tpch", user="postgres", host="localhost"
        )
    return conn

@app.route("/establishConnection")
def establishConnection():
    print("inside------reveal_support.establishConnection")
    # reveal_globals.global_connection_string = str('0.0.0.0,5432,' + reveal_globals.global_db_instance + ',,,')
    # arg = reveal_globals.global_connection_string.split(',')
    reveal_globals.global_db_engine = 'PostgreSQL'
    # if reveal_globals.global_db_engine == 'Microsoft SQL Server':
    #     try:
    #         temp = ""
    #         for elt in arg:
    #             temp = temp + elt.strip()
    #         print(temp)
    #         conn = pyodbc.connect(temp, autocommit = True)
    #         conn.autocommit = True
    #         reveal_globals.global_conn = conn
    #         return True
    #     except:
    #         #print(reveal_globals.global_connection_string)
    #         # tk.messagebox.showerror("Error: Database Connection", "Connection Could not be established. Please check Connection parameters or contact administrator.")
    #         return False
    # if reveal_globals.global_db_engine == 'PostgreSQL':



    # try:
    #     db_name = 'tpch'
    #     db_user = 'postgres'
    #     db_pass = 'root'
    #     db_host = '0.0.0.0'
    #     db_port = '5432'

    #     # Connecto to the database
    #     db_string = 'postgres://{}:{}@{}:{}/{}'.format(db_user, db_pass, db_host, db_port, db_name)
    #     db = create_engine(db_string)
    #     reveal_globals.db=db
    #     print("connection est")
    #     return True
    # except:
    #     print("connection fail")
    #     #print(reveal_globals.global_connection_string)
    #     return False

    try:
        # DB_HOST = "0.0.0.0"
        # DB_NAME = "tpch"
        # DB_USER = "postgres"
        # DB_PASS = "root"
        # DB_HOST = "database"
        # DB_NAME = "tpch"
        # DB_USER = "postgres"
        # DB_PASS = "root"
        
        # conn = connector.connect(
        #                 "sneha-354311:asia-south1:tpchmysql",
        #                 "pymysql"
        #                 ip_types = IPTypes.PUBLIC ,
        #                 user='root',
        #                 password='root', 
        #                 host='34.93.246.54', 
        #                 database='mysql'
        #                 )


        conn=getconn()
        # conn = psycopg2.connect(
        # dbname="tpch", user="postgres", password="root", host="34.100.141.5", port="5432"
        # )
        # conn = psycopg2.connect(database = DB_NAME, user = DB_USER, password = DB_PASS, host = DB_HOST,port='5432')
        #conn = psycopg2.connect(host = arg[0].strip(), port = arg[1].strip(), database = arg[2].strip(), user = arg[3].strip(), password = arg[4].strip())
        # conn.autocommit = True
        reveal_globals.global_conn = conn
        print("connected...")
        return True
    except:
        print("connection fail")
        #print(reveal_globals.global_connection_string)
        return False

# def populate_db():
#     core_relations = ['lineitem','orders','customer','nation','part','partsupp','supplier','region']
#     for tabname in core_relations:
#         cur = reveal_globals.global_conn.cursor()
#         cur.execute("drop table  if exists " + tabname + ";")
#         cur.close()

#     print("inside populate_db")
#     cur = reveal_globals.global_conn.cursor()
#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'part');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table part already exists")
#     #     pass
#     # else:
#         # there are no tables named "tableName"
#     query="	CREATE TABLE PART ( P_PARTKEY INTEGER , P_NAME VARCHAR(55), P_MFGR CHAR(25), P_BRAND CHAR(10), P_TYPE VARCHAR(25), P_SIZE INTEGER, P_CONTAINER CHAR(10), P_RETAILPRICE DECIMAL, P_COMMENT VARCHAR(23)  )"
#     cur.execute(query)
#     print("part- table created")
#     with open('part.csv','r') as csv_file:
#         print("inside with open")
#         next(csv_file)
#         cur.copy_from(csv_file, 'part', sep='|')
#     print("part- data inserted")


    
#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'REGION');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table region already exists")
#     #     pass
#     # else:
#     query="CREATE TABLE REGION ( R_REGIONKEY INTEGER , R_NAME CHAR(25), R_COMMENT VARCHAR(152) )"
#     cur.execute(query)
#     with open('region.csv','r') as csv_file:
#         print("inside with open")
#         next(csv_file)
#         cur.copy_from(csv_file, 'region', sep='|')
#     print("region- data inserted")

#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'nation');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table nation already exists")
#     #     pass
#     # else:
#     query="CREATE TABLE NATION ( N_NATIONKEY INTEGER , N_NAME CHAR(25), N_REGIONKEY BIGINT , N_COMMENT VARCHAR(152) )"
#     cur.execute(query)
#     print("nation- table created")
#     with open('nation.csv') as csv_file:
#         print("inside with open")
#         next(csv_file)
#         cur.copy_from(csv_file, 'nation', sep='|')
#     print("nation- data inserted")


#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'supplier');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table supplier already exists")
#     #     pass
#     # else:
#     query="	CREATE TABLE SUPPLIER ( S_SUPPKEY INTEGER , S_NAME CHAR(25), S_ADDRESS VARCHAR(40), S_NATIONKEY BIGINT , S_PHONE CHAR(15), S_ACCTBAL DECIMAL, S_COMMENT VARCHAR(101) )"
#     cur.execute(query)
#     print("supplier- table created")
#     with open('supplier.csv') as csv_file:
#         print("inside with open")
#         next(csv_file)
#         cur.copy_from(csv_file, 'supplier', sep='|')
#     print("supplier- data inserted")


#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'customer');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table customer already exists")
#     #     pass
#     # else:
#     query="CREATE TABLE CUSTOMER ( C_CUSTKEY INTEGER , C_NAME VARCHAR(25), C_ADDRESS VARCHAR(40), C_NATIONKEY BIGINT , C_PHONE CHAR(15), C_ACCTBAL DECIMAL, C_MKTSEGMENT CHAR(10), C_COMMENT VARCHAR(117) )"
#     cur.execute(query)
#     print("customer- table created")
#     with open('customer.csv') as csv_file:
#         print("inside with open")
#         next(csv_file)
#         cur.copy_from(csv_file, 'customer', sep='|')
#     print("customer- data inserted")
    

#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'partsupp');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table partsupp already exists")
#     #     pass
#     # else:
#     query="	CREATE TABLE PARTSUPP ( PS_PARTKEY BIGINT , PS_SUPPKEY BIGINT , PS_AVAILQTY INTEGER, PS_SUPPLYCOST DECIMAL, PS_COMMENT VARCHAR(199) )"
#     cur.execute(query)
#     print("partsupp- table created")
#     with open('partsupp.csv') as csv_file:
#         print("inside with open")
#         cur.copy_from(csv_file, 'partsupp', sep='|')
#     print("partsupp- data inserted")
    


#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'orders');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table orders already exists")
#     #     pass
#     # else:
#     query="	CREATE TABLE ORDERS ( O_ORDERKEY INTEGER , O_CUSTKEY BIGINT , O_ORDERSTATUS CHAR(1), O_TOTALPRICE DECIMAL, O_ORDERDATE DATE, O_ORDERPRIORITY CHAR(15), O_CLERK CHAR(15), O_SHIPPRIORITY INTEGER, O_COMMENT VARCHAR(79) )"
#     cur.execute(query)
#     print("orders- table created")
#     with open('orders.csv') as csv_file:
#         print("inside with open")
#         cur.copy_from(csv_file, 'orders', sep='|')
#     print("orders- data inserted")


#     # stmt ="SELECT EXISTS (SELECT FROM pg_tables WHERE schemaname = 'public' AND tablename  = 'lineitem');"
#     # cur.execute(stmt)
#     # result = cur.fetchone()
#     # if result:
#     #     print("table lineitem already exists")
#     #     pass
#     # else:
#     query="CREATE TABLE LINEITEM ( L_ORDERKEY BIGINT , L_PARTKEY BIGINT , L_SUPPKEY BIGINT , L_LINENUMBER INTEGER, L_QUANTITY DECIMAL, L_EXTENDEDPRICE DECIMAL, L_DISCOUNT DECIMAL, L_TAX DECIMAL, L_RETURNFLAG CHAR(1), L_LINESTATUS CHAR(1), L_SHIPDATE DATE, L_COMMITDATE DATE, L_RECEIPTDATE DATE, L_SHIPINSTRUCT CHAR(25), L_SHIPMODE CHAR(10), L_COMMENT VARCHAR(44) )"
#     cur.execute(query)
#     print("lineitem- table created")
#     with open('lineitem.csv','r') as csv_file:
#         print("inside with open")
#         cur.copy_from(csv_file, 'lineitem', sep='|')
#     print("lineitem- data inserted")


#     # try:
#     #     cursor.copy_from(f, table, sep=",")
#     #     conn.commit()		
#     # # Execute every command from the input file
#     # for command in sqlCommands:
#         # This will skip and report errors
#         # For example, if the tables do not yet exist, this will skip over
#         # the DROP TABLE commands
#         # try:
#     #     cur.execute(command)
#     #     # except OperationalError, msg:
#     #     #     print("Command skipped: ", msg)  
#     # return TRUE          

def reveal_support_init():
    print("inside------reveal_support.init")   
    #INITIALIZE ALL CONCERNED GLOBAL/LOCAL VARIABLES
    reveal_globals.select_inp = ""
    reveal_globals.from_inp = ""
    reveal_globals.where_inp = ""
    reveal_globals.groupby_inp = ""
    reveal_globals.orderby_inp = ""
    reveal_globals.limit_inp = ""
    reveal_globals.global_input_type = ""

    reveal_globals.global_select_op = ""
    reveal_globals.global_select_op_proc = ""
    reveal_globals.global_from_op = ""
    reveal_globals.global_where_op = ""
    reveal_globals.global_groupby_op = ""
    reveal_globals.global_orderby_op = ""
    reveal_globals.global_limit_op = ""

    reveal_globals.global_clauses_with_syntactic_changes = ""
    reveal_globals.global_number_of_query_invocations = ""
    reveal_globals.global_tot_ext_time = ""

    reveal_globals.global_select_time = ""
    reveal_globals.global_min_time = ""
    reveal_globals.global_from_time = ""
    reveal_globals.global_where_time = ""
    reveal_globals.global_join_time = ""
    reveal_globals.global_filter_time = ""
    reveal_globals.global_groupby_time = ""
    reveal_globals.global_orderby_time = ""
    reveal_globals.global_agg_time = ""
    reveal_globals.global_limit_time = ""
    reveal_globals.global_assemble_time =""

    reveal_globals.global_conn = None

    reveal_globals.global_min_button = False
    reveal_globals.global_button_string = ""

    reveal_globals.global_min_instance_dict = {}
    reveal_globals.global_miniscule_instances_dict = {}

    reveal_globals.global_proc_prev_screen = ""
    reveal_globals.global_db_prev_screen = ""

    reveal_globals.global_no_execCall = 0

    reveal_globals.global_all_relations = []
    reveal_globals.global_pk_dict = {}
    reveal_globals.global_index_dict = {}

    reveal_globals.global_core_relations = []
    reveal_globals.global_join_graph = []
    reveal_globals.global_filter_predicates = []
    reveal_globals.global_projected_attributes = []
    reveal_globals.global_groupby_attributes = []
    reveal_globals.global_aggregated_attributes = []
    reveal_globals.global_orderby_attributes = []
    reveal_globals.global_limit = 1000

    reveal_globals.global_key_lists = []
    reveal_globals.global_output_list = []
    reveal_globals.global_projection_names = []
    reveal_globals.global_groupby_flag = False
    reveal_globals.global_attrib_types = []
    reveal_globals.global_all_attribs = []
    reveal_globals.global_key_attributes = []
    reveal_globals.global_d_plus_value = {}
    reveal_globals.global_attrib_max_length = {}
    reveal_globals.global_result_dict = {}
    reveal_globals.local_other_info_dict = {}
    reveal_globals.global_other_info_dict = {}
    reveal_globals.global_extracted_info_dict = {}

    reveal_globals.global_restore_flag = False

    reveal_globals.global_test_option = False



@app.route("/extractionStart")
def extractionStart(*args):
	print("inside:   reveal_proc_support.extractionStart")
	func_from_start()

@app.route("/func_from_start")
def func_from_start():
    global status
    status="from started"
    print("inside:   reveal_proc_support.func_from_start")
    reveal_globals.local_start_time = time.time()
    reveal_globals.global_core_relations = from_clause.getCoreRelations() #aman
    print(reveal_globals.global_core_relations)
    temp = copy.deepcopy(reveal_globals.global_core_relations)
    if temp != [] and temp != False:
        reveal_globals.global_from_op = temp[0]
    else:
        return
    del temp[0]
    for elt in temp:
        reveal_globals.global_from_op = reveal_globals.global_from_op + ", " + elt
    func_from_Complete()


def func_from_Complete():
    global status
    status="from completed"
    time.sleep(0.00005)
    print("inside:   reveal_proc_support.func_from_Complete")
    reveal_globals.local_end_time = time.time()
    reveal_globals.global_from_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
    reveal_globals.global_tot_ext_time = 0
    reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
    reveal_globals.global_extracted_info_dict['min'] = extracted_part_info()
    func_min_start()

def func_min_start():
    global status
    status="minimization started"
    print("inside:   reveal_proc_support.func_min_start")
    reveal_globals.local_start_time = time.time()
	#INITIALIZATION
    if not (initialization.initialization()):
        exit(1)
    if (db_minimizer.reduce_Database_Instance(reveal_globals.global_core_relations)):
        func_min_Complete()
    else:
        reveal_globals.global_test_option = False
        # goToInitScreen()


def func_min_Complete():
    global status
    status="minimization complete"
    print("inside:   reveal_proc_support.func_min_Complete")
    reveal_globals.local_end_time = time.time()
    reveal_globals.global_min_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
    print("Minimization time ",reveal_globals.global_min_time)
    reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
    reveal_globals.global_extracted_info_dict['join'] = extracted_part_info()
    func_join_start()



def func_join_Complete():
    reveal_globals.local_end_time = time.time()
    reveal_globals.global_join_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
    reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
    print("inside:   reveal_proc_support.func_join_Complete")
    reveal_globals.global_extracted_info_dict['filter'] = extracted_part_info()
    func_filter_start()


def func_join_start():
	print("inside:   reveal_proc_support.func_join_start")
	reveal_globals.local_start_time = time.time()
	where_clause.get_join_graph() #Returns JOIN GRAPH in Adjacency List format
	first_occur = True
	for elt in reveal_globals.global_join_graph:
		for i in range(1, len(elt)):
			if first_occur == True:
				reveal_globals.global_where_op = elt[0] + ' = ' + elt[i]
				first_occur = False
			else:
				reveal_globals.global_where_op = reveal_globals.global_where_op + ' and ' + elt[0] + ' = ' + elt[i]
	func_join_Complete()
	
def func_assemble_Complete():
    print("inside:   reveal_proc_support.func_assemble_Complete")
    reveal_globals.local_end_time = time.time()
    reveal_globals.global_assemble_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
    reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
    reveal_globals.global_select_op = reveal_globals.global_select_op.replace('as l_orderkey', '')	
    print("end")
    print("$$$$****$$$$")
    #time.sleep(50)
    error_handler.restore_database_instance()



def func_assemble_start():
    print("inside:   reveal_proc_support.func_assemble_start")
    reveal_globals.local_start_time = time.time()
    output = "Select " + reveal_globals.global_select_op + "\n" + "From "  + reveal_globals.global_from_op + "\n" + "Where " + reveal_globals.global_where_op + "\n" + "Group By "+ reveal_globals.global_groupby_op + "\n" + "Order By " + reveal_globals.global_orderby_op + "\n" + "Limit " + reveal_globals.global_limit_op + ";"
    print('EXTRACTED OUTPUT QUERY :')
    reveal_globals.output1=output
    print(reveal_globals.output1)
    func_assemble_Complete()  #changes made here0
	

def func_limit_Complete():
    print("inside:   reveal_proc_support.func_limit_Complete")
    reveal_globals.local_end_time = time.time()
    reveal_globals.global_limit_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
    reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
    func_assemble_start()
    #jfjhgfhg
    


def func_limit_start():
	print("inside:   reveal_proc_support.func_limit_start")
	reveal_globals.local_start_time = time.time()
	reveal_globals.global_limit = limit.get_limit()
	if reveal_globals.global_limit is not None:
		reveal_globals.global_limit_op = str(reveal_globals.global_limit)
	func_limit_Complete()


def func_orderby_Complete():
	print("inside:   reveal_proc_support.func_orderby_Complete")
	reveal_globals.local_end_time = time.time()
	reveal_globals.global_orderby_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
	reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
	reveal_globals.global_extracted_info_dict['limit'] = extracted_part_info()
	func_limit_start()


def func_orderby_start():
	print("inside:   reveal_proc_support.func_orderby_start")
	reveal_globals.local_start_time = time.time()
	reveal_globals.global_orderby_attributes = orderby_clause.get_orderby_attributes()
	first_occur = True
	for elt in reveal_globals.global_orderby_attributes:
		if first_occur == True:
			reveal_globals.global_orderby_op = reveal_globals.global_output_list[elt[0].index] + ' ' + elt[1]
			first_occur = False
		else:
			reveal_globals.global_orderby_op = reveal_globals.global_orderby_op + ', ' + reveal_globals.global_output_list[elt[0].index] + ' ' + elt[1]
	func_orderby_Complete()


def func_agg_Complete():
	print("inside:   reveal_proc_support.func_agg_Complete")
	reveal_globals.global_select_op_proc = reveal_globals.global_select_op
	reveal_globals.local_end_time = time.time()
	reveal_globals.global_agg_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
	reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
	reveal_globals.global_extracted_info_dict['order by'] = extracted_part_info()
	func_orderby_start()


def func_agg_start():
    print("inside:   reveal_proc_support.func_agg_start")
    reveal_globals.local_start_time = time.time()
    reveal_globals.global_aggregated_attributes = aggregation.get_aggregation()
    refine_Query()   
    func_agg_Complete()


def refine_Query():
	print("inside:   reveal_proc_support.refine_Query")
	for i in range(len(reveal_globals.global_projected_attributes)):
		attrib = reveal_globals.global_projected_attributes[i]
		if attrib in reveal_globals.global_key_attributes and attrib in reveal_globals.global_groupby_attributes:
			if not ('sum' in reveal_globals.global_aggregated_attributes[i][1] or 'count' in reveal_globals.global_aggregated_attributes[i][1]):
				reveal_globals.global_aggregated_attributes[i] = (reveal_globals.global_aggregated_attributes[i][0], '')
	temp_list = copy.deepcopy(reveal_globals.global_groupby_attributes)
	for attrib in temp_list:
		if attrib not in reveal_globals.global_projected_attributes:
			try:
				reveal_globals.global_groupby_attributes.remove(attrib)
			except:
				pass
			continue
		remove_flag = True
		for elt in reveal_globals.global_aggregated_attributes:
			if elt[0] == attrib and (not ('sum' in elt[1] or 'count' in elt[1])):
				remove_flag = False
				break
		if remove_flag == True:
			try:
				reveal_globals.global_groupby_attributes.remove(attrib)
			except:
				pass
	#UPDATE OUTPUTS
	first_occur = True
	reveal_globals.global_groupby_op = ''
	for i in range(len(reveal_globals.global_groupby_attributes)):
		elt = reveal_globals.global_groupby_attributes[i]
		if first_occur == True:
			reveal_globals.global_groupby_op = elt
			first_occur = False
		else:
			reveal_globals.global_groupby_op = reveal_globals.global_groupby_op + ", " + elt
	first_occur = True
	for i in range(len(reveal_globals.global_projected_attributes)):
		elt = reveal_globals.global_projected_attributes[i]
		reveal_globals.global_output_list.append(copy.deepcopy(elt))
		if reveal_globals.global_aggregated_attributes[i][1] != '':
			elt = reveal_globals.global_aggregated_attributes[i][1] + '(' + elt + ')'
			if 'count' in reveal_globals.global_aggregated_attributes[i][1]:
				elt = reveal_globals.global_aggregated_attributes[i][1]
			reveal_globals.global_output_list[-1] = copy.deepcopy(elt)
		if elt != reveal_globals.global_projection_names[i] and reveal_globals.global_projection_names[i] != '':
			elt = elt + ' as ' + reveal_globals.global_projection_names[i]
			reveal_globals.global_output_list[-1] = copy.deepcopy(reveal_globals.global_projection_names[i])
		if first_occur == True:
			reveal_globals.global_select_op = elt
			first_occur = False
		else:
			reveal_globals.global_select_op = reveal_globals.global_select_op + ", " + elt	
	return


def func_groupby_Complete():
    print("inside:   reveal_proc_support.func_groupby_Complete")
    reveal_globals.local_end_time = time.time()
    reveal_globals.global_groupby_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
    reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
    reveal_globals.global_extracted_info_dict['agg'] = extracted_part_info()
    func_agg_start()


def func_groupby_start():
    print("inside:   reveal_proc_support.func_groupby_start")
    reveal_globals.local_start_time = time.time()
    first_occur = True
    reveal_globals.global_groupby_attributes, reveal_globals.global_groupby_flag = groupby_clause.getGroupByAttributes()
    for i in range(len(reveal_globals.global_groupby_attributes)):
        elt = reveal_globals.global_groupby_attributes[i]
        if first_occur == True:
            reveal_globals.global_groupby_op = elt
            first_occur = False
        else:
            reveal_globals.global_groupby_op = reveal_globals.global_groupby_op + ", " + elt
    func_groupby_Complete()


def func_project_Complete():
	print("inside:   reveal_proc_support.func_project_Complete")
	reveal_globals.local_end_time = time.time()
	reveal_globals.global_select_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
	reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
	reveal_globals.global_extracted_info_dict['group by'] = extracted_part_info()
	func_groupby_start()


def func_project_start():
	print("inside:   reveal_proc_support.func_project_start")
	reveal_globals.local_start_time = time.time()
	reveal_globals.global_projected_attributes, reveal_globals.global_projection_names = projection.getProjectedAttributes()
	first_occur = True
	for i in range(len(reveal_globals.global_projected_attributes)):
		elt = reveal_globals.global_projected_attributes[i]
		reveal_globals.global_output_list.append(copy.deepcopy(elt))
		if elt != reveal_globals.global_projection_names[i] and reveal_globals.global_projection_names[i] != '':
			elt = elt + ' as ' + reveal_globals.global_projection_names[i]
			reveal_globals.global_output_list[-1] = copy.deepcopy(reveal_globals.global_projection_names[i])
		if first_occur == True:
			reveal_globals.global_select_op_proc = elt
			first_occur = False
		else:
			reveal_globals.global_select_op_proc = reveal_globals.global_select_op_proc + ", " + elt
	func_project_Complete()


def func_filter_Complete():
	print("inside:   reveal_proc_support.func_filter_Complete")
	reveal_globals.local_end_time = time.time()
	reveal_globals.global_filter_time = str(round(reveal_globals.local_end_time - reveal_globals.local_start_time, 1)) + "      sec"
	reveal_globals.global_tot_ext_time += reveal_globals.local_end_time - reveal_globals.local_start_time
	reveal_globals.global_extracted_info_dict['projection'] = extracted_part_info()
	func_project_start()


def func_filter_start():
	print("inside:   reveal_proc_support.func_filter_start")
	reveal_globals.local_start_time = time.time() #aman
	reveal_globals.global_filter_predicates = where_clause.get_filter_predicates()
	print("where time: ", time.time() - reveal_globals.local_start_time) #aman
	for elt in reveal_globals.global_filter_predicates:
		predicate = ''
		if elt[2].strip() == 'range':
			if '-' in str(elt[4]):
				predicate = elt[1] + " between "  + str(elt[3]) + " and " + str(elt[4])
			else:
				predicate = elt[1] + " between "  + " '" + str(elt[3]) + "'" + " and " + " '" + str(elt[4]) + "'"
		elif elt[2].strip() == '>=':
			if '-' in str(elt[3]):
				predicate = elt[1] + " " + str(elt[2]) + " '" + str(elt[3]) + "' "
			else:
				predicate = elt[1] + " " + str(elt[2]) + " " + str(elt[3])
		elif 'equal' in elt[2] or 'like' in elt[2].lower() or '-' in str(elt[4]):
			predicate = elt[1] + " " + str(elt[2]).replace('equal', '=') + " '" + str(elt[4]) + "'"
		else:
			predicate = elt[1] + ' ' + str(elt[2]) + ' ' + str(elt[4])
		if reveal_globals.global_where_op == '':
			reveal_globals.global_where_op = predicate
		else:
			reveal_globals.global_where_op = reveal_globals.global_where_op + " and " + predicate
	func_filter_Complete()



'''
if __name__ == '__main__':
    reveal_vp_start_gui()
 
 '''


@app.route("/")
def session_page():
    reveal_support_init()
    establishConnection()
    return render_template('page1.html')

@app.route("/query_input_page",methods=['POST','GET'])
def query_page():
    # if(request.method=="POST"):
    #     # session["name"]=n     #session is stored in form of doctionary
    #     session["i_query"]=[]
    #     session["o_query"]=[]
    # else:
    #     pass
    #     # n=request.form.get("uname")
    return render_template('page1.html')
    
@app.route("/query_process_page",methods=['POST','GET'])
def query_process_page():
    q=request.form.get("QUERY")
    reveal_globals.query1=q
    reveal_vp_start_gui()
    op=reveal_globals.output1
    session["i_query"]=reveal_globals.query1
    session["o_query"]=op
    return redirect('/query_output_page')


@app.route("/query_output_page")
def query_output_page():
    # op=reveal_globals.output1
    # session["i_query"]=reveal_globals.query1
    # session["o_query"]=op
    return render_template('page2.html',output_query=session["o_query"],input_query=session["i_query"])


@app.route("/back_to_query_page")
def back_to_query_page():
    reveal_support_init()
    return redirect("/query_input_page")


@app.before_first_request
def before_first_request():
    threading.Thread(target=update_load).start()


def update_load():
    with app.app_context():
        while True:
            time.sleep(0.05)
            turbo.push(turbo.replace(render_template('loadavg.html'), 'load'))


@app.context_processor
def inject_load():
    return {'from_time':reveal_globals.global_from_time,
     'minimization_time': reveal_globals.global_min_time,
    'select_time':reveal_globals.global_select_time,
    'where_time':reveal_globals.global_where_time,
    'join_time':reveal_globals.global_join_time,
    'filter_time':reveal_globals.global_filter_time,
    'groupby_time':reveal_globals.global_groupby_time, 
    'orderby_time':reveal_globals.global_orderby_time,
    'agg_time':reveal_globals.global_agg_time,
    'limit_time':reveal_globals.global_limit_time,
    'assemble_time':reveal_globals.global_assemble_time,
    'from_op':reveal_globals.global_from_op,
    'select_op':reveal_globals.global_select_op,
    'where_op':reveal_globals.global_where_op,
    'groupby_op':reveal_globals.global_groupby_op,
    'orderby_op':reveal_globals.global_orderby_op,
    'limit_op':reveal_globals.global_limit_op,
    }




if __name__=='__main__':
    app.run()






